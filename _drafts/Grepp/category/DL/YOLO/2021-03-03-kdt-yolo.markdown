---
layout: post
title:  "YOLO 실습"
date:   2021-03-03 01:00:00 +0900
category: "Grepp/KDT"
tag: "Deep Learning"
---

## 설치 및 예제 실행 - YOLO Linux 빌드 및 실행

### Alexey YOLO
- Original YOLO는 pjreddie의 YOLO였으나, 자신은 YOLO가 전쟁 등에 사용되는 것을 보고 더 이상 YOLO를 개발하지 않겠다고 선언
- 그 후로 Alexey가 이어 받아 Bug Fix와 릴리즈를 하고 있다.
- Pjreddie의 YOLO와 달리 Alexey는 Windows 또한 지원하며 Alexey만의 YOLOv4 버전을 출시하였다.


### Alexey YOLO 설치 방법 - Linux
- Alexey YOLO를 리눅스에 설치하기 위해서는 다음 디팬던시가 충족되어야 한다.
    - ROS Kinetic(16.04) 또는 Melodic(18.04)
- 다음 명령어를 이용하여 Alexey YOLO repositiory를 clone 한다.
```bash
$ cd ~/Desktop
$ git clone https://github.com/AlexeyAB/darknet.git
$ cd ./darknet
$ git checkout darknet_yolo_v3
```
- Makefile을 열어 4라인의 OPENCV만 1로 변경한다.
- CUDA를 사용할 경우 CUDA와 CUDNN 또한 1로 변경한다.
- 그리고 darknet 프로젝트를 clone한 위치에서 명령을 입력한다.
```bash
$ make
```


### Alexey YOLO 예제 실행 - Linux
- 다음 명령을 차례로 입력한다.
```bash
$ cd ~/Desktop/darknet
$ wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3.cfg
$ wget https://pjreddie.com/media/files/yolov3.weights
$ ./darknet detector test ./cfg/cocoa.data ./yolov3.cfg ./yolov3.weights data/dog.jpg -i 0 -thresh 0.25
```


## Alexey - YOLO 학습

### YOLO 학습
- YOLO를 학습시키려면 어떻게 해야 하는가? 순서는 다음과 같아.
    1. 필요한 사진 데이터를 모은다.
    2. 사진 데이터에 라벨링을 한다.
    3. 학습시킬 버전을 선택한다.
    4. 학습한다.
- 그런데, 여기서 라벨링이 되게 어렵다.
    - 각 사진에서 찾을 객체의 위치를 x, y, w, h로 만들어야 하는데, 이게 여간 번거로운 일이 아니다.
    - 그래서 Alexey님께서 친히 라벨링 프로그램을 제작, 배포하였는데, 그 프로그램이 YOLO Mark이다.


### YOLO Mark 설치 - Linux
- 다음 명령어를 이용하여 Alexey YOLO Mark repositiory를 clone한다.
```bash
$ cd ~/Desktop
$ git clone https://github.com/AlexeyAB/Yolo_mark.git
```
- 그리고 clone 된 디렉토리로 들어가 다음 명령을 차례로 실행한다.
```bash
$ cmake .
$ make
$ chmod +x ./linux_mark.sh
```


### YOLO Mark 사용방법 - Linux
- 우선 x64/Release/data/obj.names 파일을 열어 분류할 물체의 이름을 적어준다.
    - 만약 비행기와 새를 분류할 것이라면 첫 줄에 airplane, 그리고 두 번쨰 줄에 bird라고 적고 저장한다.
    - 그러면 첫 줄에 적은 airplane은 앞으로 0번 오브젝트가 되고, bird는 1번 오브젝트가 된다.
- 그리고 x64/Release/data/obj.data를 열어 class= 이 부분만 변경한다.
    - 지금은 비행기와 새를 구분하는 모델을 만들고 있으므로, 비행기, 새 총 2개이다.
    - 그러므로 classe=2를 기록 후 저장한다.
    - 우선 다른 것은 바꾸지 않는다.
- 마지막으로 라벨링 할 이미지를 정리하여 yolo_mark 디렉토리 x64/Release/data/img에 넣는다.
- 그리고 linux_mark.sh를 실행한다.
    - Image num은 라벨링할 이미지를 불러올 수 있는 스크롤이다. 아까 img 디렉토리에 넣은 이미지를 순차적으로 불러오며, 중간에 썸네일을 클릭하는 방법으로 해당 이미지로 이동할 수 있다.
    - Object ID는 지금 표시할 객체가 무엇인지 설정하는 스크롤이다.
    - 사진 위에 드래그를 해보면 드래그한 범위만큼 직사각형이 생성되며 거기에 `0 - airplane`이라고 붇는 것을 알 수 있다.
    - 그리고 object id 스크롤을 우측으로 당긴 후 0에서 1이 되는 것을 확인하고 다시 사진 위에 드래그 해보면 우측처럼 드래그한 범위만큼 직사가각형이 생성되며 거기에 `1 - bird라고 붇는 것을 알 수 있다.
    - 이렇게 드래그를 하고 다음 사진으로 넘어가면, 프로그램 상단 썸네일에 녹색 체크 표시가 뜬다. 해당 체크는 라벨링 계산을 완료했고, 파일을 만들어 저장했다는 뜻이다.
    - 실제로 해당 이미지 파일이 있는 경로로 가보면, txt 파일이 생성되어 있고, 해당 텍스트에 방금 라벨링한 데이터가 들어 있는 것을 확인 할 수 있다.
    - 단축키 h를 누르면 작업들을 간소화 시켜줄 단축키에 대해 잘 나와있다.


### YOLO 학습 방법 - Linux
- YOLO Mark를 통한 라벨링 작업이 끝났다면, 이제 학습 모델을 골라야 한다.
- 각 모델마다 특징이 있는데,
    - YOLOv2는 YOLOv3보다 속도가 빠르다.
    - Tiny는 일반보다 정확도가 낮으나, 속도는 훨씬 빠르다.
    - YOLOv4는 YOLOv3보다 정확도가 상승되었다.
- 우리는 ROS에서 YOLO를 사용할 것을 감안하여 모델을 골라야 한다.
    - 유서 깊은 YOLO ROS package인 darknet_ros가 있는데, 해당 패키지는 YOLOv3까지만 지원한다. 게다가 TX2로 YOLOv3를 구동시 fps가 2~3 정도 나오므로, 해당 부분을 감안하여 YOLOv2또는 YOLOv2-tiny를 선택하는 것이 좋다.
    - Jetpack 3.2.1 버전이 설치된 B2에서는 최신 버전의 Alexey YOLO 설치가 불가능하기 때문에, v4 사용이 불가능하다.
- 모델을 선택했으면, 그에 해당하는 사전 학습 파일을 다운받는다.
    - YOLOv2 & YOLOv2-tiny: http://pjreddie.com/media/files/darknet19_448.conv.23
- cfg 파일은 다음 URL에서 다운받는다.
    - https://raw.githubusercontent.com/AlexeyAB/darknet/darknet_yolo_v3/cfg/yolov2-tiny.cfg
- 다운 받은 cfg파일을 열어 다음을 수정한다.
    - 3번째 줄: batch=1 ---> batch=64
    - 4번째 줄: subdivision=1 ---> subdivisions=8
    - 119번째 줄: filters=425 ---> filters={(분류할 class 수 + 5)*5}
    - 125번째 줄: classes=80 ---> classes={분류할 class 수}
- 다음 에러가 뜰 시 batch 값을 낮추거나, subdivisions 값을 늘리면 된다.
```bash
darknet: ./src/utils.c:331: void error(const char*): Assertion '0' failed.
```
- 수정이 완료되었으면, 다음은 드디어 학습을 시작한다.
```bash
$ cd ~/Desktop/darknet
$ ./darknet detector train $HOME/Desktop/Yolo_mark/x64/Release/data/obj.data cfg/yolov2-tiny.cfg darknet19_448.conv.23
```
- Tips
    - YOLO 매뉴얼에 학습을 시키지 위한 클래스당 최소 이미지의 개수는 2천개라 적혀있으나, 실제로 여러가지 테스트 해본 결과, 300~400장 정도면 인식률이 아주 나쁘지 않은 것을 확인
    - 여기서 이미지의 개수는 모두 다른 자세, 다른 환경의 이미지를 의미한다.


### YOLO 학습 방법 - Windows
- 첨부 파일 darknet.zip 다운로드 후 압축 해제
- 해당 버전은 YOLO CPU 버전이다.
- YOLO Mark 사용법
    - darknet/yolo_mark.cmd 실행
- 학습 방법
    - YOLOv4: darknet/yolov4_train.cmd 실행
    - YOLOv3: darknet/yolov2_train.cmd 실행
    - YOLOv2: darknet/yolov3_train.cmd 실행
- 이미지 감지 예제
    - YOLOv4: darknet/yolov4_image_detect_example.bat
    - YOLOv3: darknet/yolov3_image_detect_example.bat
    - YOLOv2: darknet/yolov2_image_detect_example.bat



## YOLO 실전 사용 - darknet_ros 사용법

### darknet_ros 패키지
- darknet_ros 패키지
    - YOLO를 ROS에서 쉽게 사용할 수 있게 제작된 패키지
    - 현재 ROS1에 대해서는 더이상 업데이트가 되고 있지 않다.
    - YOLOv3까지 구동 가능하며, TX2 보드 Jetpack v3.x.x에서 ROS와 동시에 사용할 때 애용되는 패키지 중 하나


### darknet_ros 패키지 설치
- 다음 명령어를 차례로 입력하여 darknet_ros를 설치한다.
```bash
$ cd {ROS 사용자 workspace}/src
$ git clone https://github.com/leggedrobotics/darknet_ros.git
$ cd ./darknet_ros
$ git submodule init
$ git submodule update
$ cm
```
- catkin_make 시에 자동으로 YOLOv2, YOLOv2-tiny, YOLOv3 weight 파일을 다운로드 한다.
- 만약 다운로드를 하고 싶지 않다면, darknet_ros/darknet_ros/CMakeLists.txt 파일을 수정한다.
    - 231, 239, 253줄 주석처리 시, weight 파일을 다운받지 않는다.


### darknet_ros 사용법
- 구조
    - 카메라 노드 ---(카메라 이미지) ---> darknet_ros
    - darknet_ros ---(박스가 표시된 이미지/바운딩박스 위치 크기 정보/감지된 개체수) ---> Main

